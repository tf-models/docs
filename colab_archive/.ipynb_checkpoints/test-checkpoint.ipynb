{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "choice-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "horizontal-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare input shape \n",
    "# in_dim = shape=([None, None, 3])\n",
    "raw_input = (32, 32, 3)\n",
    "input = tf.keras.Input(raw_input)\n",
    "\n",
    "# Block 1\n",
    "x = tf.keras.layers.Conv2D(32, 3, strides=2, activation=\"relu\")(input)\n",
    "x = tf.keras.layers.MaxPooling2D(3)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "# Block 2\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "# Now that we apply global max pooling.\n",
    "gap = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "output = tf.keras.layers.Dense(10)(gap)\n",
    "\n",
    "# bind all\n",
    "func_model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "immediate-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 15, 15, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPoolin  (None, 5, 5, 32)          0         \n",
      "g2D)                                                             \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Ba  (None, 5, 5, 32)          128       \n",
      "tchNormalization)                                                \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Ba  (None, 3, 3, 64)          256       \n",
      "tchNormalization)                                                \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_3 (Glo  (None, 64)                0         \n",
      "balMaxPooling2D)                                                 \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 20,426\n",
      "Trainable params: 20,234\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "opening-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSubClassing(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModelSubClassing, self).__init__()\n",
    "\n",
    "        # define all layers in init\n",
    "        # Layer of Block 1\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, strides=2, activation=\"relu\")\n",
    "        self.max1  = tf.keras.layers.MaxPooling2D(3)\n",
    "        self.bn1   = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        # Layer of Block 2\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")\n",
    "        self.bn2   = tf.keras.layers.BatchNormalization()\n",
    "        self.drop  = tf.keras.layers.Dropout(0.3)\n",
    "\n",
    "        # GAP, followed by Classifier\n",
    "        self.gap   = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.keras.layers.Dense(num_classes)        \n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        # forward pass: block 1 \n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # forward pass: block 2 \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # droput followed by gap and classifier\n",
    "        x = self.drop(x)\n",
    "        x = self.gap(x)\n",
    "        return self.dense(x)\n",
    "    \n",
    "    def build_graph(self, raw_shape):\n",
    "        x = tf.keras.layers.Input(shape=raw_shape)\n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "virgin-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 15, 15, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPoolin  (None, 5, 5, 32)          0         \n",
      "g2D)                                                             \n",
      "_________________________________________________________________\n",
      "batch_normalization_172 (Ba  (None, 5, 5, 32)          128       \n",
      "tchNormalization)                                                \n",
      "_________________________________________________________________\n",
      "conv2d_173 (Conv2D)          (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Ba  (None, 3, 3, 64)          256       \n",
      "tchNormalization)                                                \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_15  (None, 64)                0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 20,426\n",
      "Trainable params: 20,234\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dim = (32, 32, 3)\n",
    "msc = ModelSubClassing(10)\n",
    "# .build(raw_input)\n",
    "msc.build_graph(dim).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "photographic-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# x_train.shape, y_train.shape: (60000, 28, 28) (60000,)\n",
    "# x_test.shape,  y_test.shape : (10000, 28, 28) (10000,)\n",
    "\n",
    "# train set / data \n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_train = np.repeat(x_train, 3, axis=-1)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "# train set / target \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "\n",
    "\n",
    "# validation set / data \n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "x_test = np.repeat(x_test, 3, axis=-1)\n",
    "x_test = x_test.astype('float32') / 255\n",
    "# validation set / target \n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subsequent-musical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Sub-Classing API\n"
     ]
    }
   ],
   "source": [
    "print('\\nModel Sub-Classing API')\n",
    "sub_classing_model = ModelSubClassing(10)\n",
    "# sub_classing_model.compile(\n",
    "#           loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "#           metrics   = tf.keras.metrics.CategoricalAccuracy(),\n",
    "#           optimizer = tf.keras.optimizers.Adam())\n",
    "# # fit \n",
    "# sub_classing_model.fit(x_train, y_train, batch_size=128, epochs=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-philosophy",
   "metadata": {},
   "source": [
    "# Layer: ConvModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "spare-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_num, kernel_size, strides, padding='same'):\n",
    "        super(ConvModule, self).__init__()\n",
    "        # conv layer\n",
    "        self.conv = tf.keras.layers.Conv2D(kernel_num, \n",
    "                        kernel_size=kernel_size, \n",
    "                        strides=strides, padding=padding)\n",
    "\n",
    "        # batch norm layer\n",
    "        self.bn   = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "    \n",
    "    def build_graph(self, raw_shape):\n",
    "        x = tf.keras.layers.Input(shape=raw_shape)\n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dying-vault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_176 (Conv2D)          (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Ba  (None, 32, 32, 96)        384       \n",
      "tchNormalization)                                                \n",
      "_________________________________________________________________\n",
      "tf.nn.relu_1 (TFOpLambda)    (None, 32, 32, 96)        0         \n",
      "=================================================================\n",
      "Total params: 3,072\n",
      "Trainable params: 2,880\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cm = ConvModule(96, (3,3), (1,1)).build_graph(dim)\n",
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attractive-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable weights: 4\n"
     ]
    }
   ],
   "source": [
    "cm = ConvModule(96, (3,3), (1,1))\n",
    "y = cm(tf.ones(shape=(2,32,32,3))) # first call to the `cm` will create weights\n",
    "\n",
    "print(\"weights:\", len(cm.weights))\n",
    "print(\"trainable weights:\", len(cm.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-macedonia",
   "metadata": {},
   "source": [
    "# Layer: InceptionModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "novel-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size1x1, kernel_size3x3):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        # two conv modules: they will take same input tensor \n",
    "        self.conv1 = ConvModule(kernel_size1x1, kernel_size=(1,1), strides=(1,1))\n",
    "        self.conv2 = ConvModule(kernel_size3x3, kernel_size=(3,3), strides=(1,1))\n",
    "        self.cat   = tf.keras.layers.Concatenate()\n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x_1x1 = self.conv1(input_tensor)\n",
    "        x_3x3 = self.conv2(input_tensor)\n",
    "        x = self.cat([x_1x1, x_3x3])\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-testament",
   "metadata": {},
   "source": [
    "# Layer: DownSampleModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "headed-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(DownsampleModule, self).__init__()\n",
    "\n",
    "        # conv layer\n",
    "        self.conv3 = ConvModule(kernel_size, kernel_size=(3,3), \n",
    "                         strides=(2,2), padding=\"valid\") \n",
    "\n",
    "        # pooling layer \n",
    "        self.pool  = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), \n",
    "                         strides=(2,2))\n",
    "        self.cat   = tf.keras.layers.Concatenate()\n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "\n",
    "        # forward pass \n",
    "        conv_x = self.conv3(input_tensor, training=training)\n",
    "        pool_x = self.pool(input_tensor)\n",
    "\n",
    "        # merged\n",
    "        return self.cat([conv_x, pool_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-bermuda",
   "metadata": {},
   "source": [
    "# Model: +Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "consolidated-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class MiniInception(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MiniInception, self).__init__()\n",
    "\n",
    "        # the first conv module\n",
    "        self.conv_block = ConvModule(96, (3,3), (1,1))\n",
    "\n",
    "        # 2 inception module and 1 downsample module\n",
    "        self.inception_block1  = InceptionModule(32, 32)\n",
    "        self.inception_block2  = InceptionModule(32, 48)\n",
    "        self.downsample_block1 = DownsampleModule(80)\n",
    "  \n",
    "        # 4 inception module and 1 downsample module\n",
    "        self.inception_block3  = InceptionModule(112, 48)\n",
    "        self.inception_block4  = InceptionModule(96, 64)\n",
    "        self.inception_block5  = InceptionModule(80, 80)\n",
    "        self.inception_block6  = InceptionModule(48, 96)\n",
    "        self.downsample_block2 = DownsampleModule(96)\n",
    "\n",
    "        # 2 inception module \n",
    "        self.inception_block7 = InceptionModule(176, 160)\n",
    "        self.inception_block8 = InceptionModule(176, 160)\n",
    "\n",
    "        # average pooling\n",
    "        self.avg_pool = tf.keras.layers.AveragePooling2D((7,7))\n",
    "\n",
    "        # model tail\n",
    "        self.flat      = tf.keras.layers.Flatten()\n",
    "        self.classfier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "        self.test = True\n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False, **kwargs):\n",
    "        \n",
    "        # forward pass \n",
    "        x = self.conv_block(input_tensor)\n",
    "        x = self.inception_block1(x)\n",
    "        x = self.inception_block2(x)\n",
    "        x = self.downsample_block1(x)\n",
    "\n",
    "\n",
    "        x = self.inception_block3(x)\n",
    "        x = self.inception_block4(x)\n",
    "        x = self.inception_block5(x)\n",
    "        x = self.inception_block6(x)\n",
    "        x = self.downsample_block2(x)\n",
    "\n",
    "\n",
    "        x = self.inception_block7(x)\n",
    "        x = self.inception_block8(x)\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "\n",
    "        x = self.flat(x)\n",
    "        return self.classfier(x)\n",
    "\n",
    "\n",
    "    def build(self, x):\n",
    "        x = tf.keras.layers.Input(shape=x.shape[1:])\n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "smooth-student",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv_module_422 (ConvModule  (None, 32, 32, 96)        3072      \n",
      ")                                                                \n",
      "_________________________________________________________________\n",
      "inception_module_176 (Incep  (None, 32, 32, 64)        31040     \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "inception_module_177 (Incep  (None, 32, 32, 80)        30096     \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "downsample_module_44 (Downs  (None, 15, 15, 160)       58000     \n",
      "ampleModule)                                                     \n",
      "_________________________________________________________________\n",
      "inception_module_178 (Incep  (None, 15, 15, 160)       87840     \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "inception_module_179 (Incep  (None, 15, 15, 160)       108320    \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "inception_module_180 (Incep  (None, 15, 15, 160)       128800    \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "inception_module_181 (Incep  (None, 15, 15, 144)       146640    \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "downsample_module_45 (Downs  (None, 7, 7, 240)         124896    \n",
      "ampleModule)                                                     \n",
      "_________________________________________________________________\n",
      "inception_module_182 (Incep  (None, 7, 7, 336)         389520    \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "inception_module_183 (Incep  (None, 7, 7, 336)         544656    \n",
      "tionModule)                                                      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_22 (Avera  (None, 1, 1, 336)         0         \n",
      "gePooling2D)                                                     \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                3370      \n",
      "=================================================================\n",
      "Total params: 1,656,250\n",
      "Trainable params: 1,652,826\n",
      "Non-trainable params: 3,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones(shape=(0,*raw_input))\n",
    "y = MiniInception().build(x)\n",
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "further-honduras",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot iterate over a Tensor with unknown first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-a458d1f4a199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniInception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-fd6778422bc7>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(self, raw_shape)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.8/site-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m     input_layer_config.update(\n\u001b[1;32m    382\u001b[0m         {'batch_size': batch_size, 'input_shape': shape})\n\u001b[0;32m--> 383\u001b[0;31m   \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_layer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;31m# Return tensor including `_keras_history`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.8/site-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.8/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot iterate over a scalar.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m       raise TypeError(\n\u001b[0m\u001b[1;32m    343\u001b[0m           'Cannot iterate over a Tensor with unknown first dimension.')\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_KerasTensorIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot iterate over a Tensor with unknown first dimension."
     ]
    }
   ],
   "source": [
    "cm = MiniInception().build_graph(x)\n",
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "colored-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mini_inception_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_module_115 (ConvModule  multiple                  3072      \n",
      ")                                                                \n",
      "_________________________________________________________________\n",
      "inception_module_48 (Incept  multiple                  31040     \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_49 (Incept  multiple                  30096     \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "downsample_module_12 (Downs  multiple                  58000     \n",
      "ampleModule)                                                     \n",
      "_________________________________________________________________\n",
      "inception_module_50 (Incept  multiple                  87840     \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_51 (Incept  multiple                  108320    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_52 (Incept  multiple                  128800    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_53 (Incept  multiple                  146640    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "downsample_module_13 (Downs  multiple                  124896    \n",
      "ampleModule)                                                     \n",
      "_________________________________________________________________\n",
      "inception_module_54 (Incept  multiple                  389520    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_55 (Incept  multiple                  544656    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Averag  multiple                  0         \n",
      "ePooling2D)                                                      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  3370      \n",
      "=================================================================\n",
      "Total params: 1,656,250\n",
      "Trainable params: 1,652,826\n",
      "Non-trainable params: 3,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "raw_input = (32, 32, 3)\n",
    "\n",
    "# init model object\n",
    "cm = MiniInception()\n",
    "\n",
    "# The first call to the `cm` will create the weights\n",
    "y = cm(tf.ones(shape=(0,*raw_input))) \n",
    "\n",
    "cm.summary()\n",
    "\n",
    "# # print summary\n",
    "# cm.build_graph(raw_input).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "corporate-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv_module_115 (ConvModule  (None, 32, 32, 96)        3072      \n",
      ")                                                                \n",
      "_________________________________________________________________\n",
      "inception_module_48 (Incept  (None, 32, 32, 64)        31040     \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_49 (Incept  (None, 32, 32, 80)        30096     \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "downsample_module_12 (Downs  (None, 15, 15, 160)       58000     \n",
      "ampleModule)                                                     \n",
      "_________________________________________________________________\n",
      "inception_module_50 (Incept  (None, 15, 15, 160)       87840     \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_51 (Incept  (None, 15, 15, 160)       108320    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_52 (Incept  (None, 15, 15, 160)       128800    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_53 (Incept  (None, 15, 15, 144)       146640    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "downsample_module_13 (Downs  (None, 7, 7, 240)         124896    \n",
      "ampleModule)                                                     \n",
      "_________________________________________________________________\n",
      "inception_module_54 (Incept  (None, 7, 7, 336)         389520    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "inception_module_55 (Incept  (None, 7, 7, 336)         544656    \n",
      "ionModule)                                                       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Averag  (None, 1, 1, 336)         0         \n",
      "ePooling2D)                                                      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                3370      \n",
      "=================================================================\n",
      "Total params: 1,656,250\n",
      "Trainable params: 1,652,826\n",
      "Non-trainable params: 3,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cm.build_graph(raw_input).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-lexington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "conceptual-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(tf.keras.layers.Layer):\n",
    "#     def __init__(self, units):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.units = units\n",
    "\n",
    "#     def build(self, _):\n",
    "#         self.output_layer = Dense(units=self.units)\n",
    "\n",
    "#     def call(self, X):\n",
    "#         return self.output_layer(X)\n",
    "\n",
    "# class Encoder(Layer):\n",
    "#     def __init__(self, units):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.output_layer = Dense(units=units, activation=tf.nn.relu)\n",
    "\n",
    "#     def call(self, X):\n",
    "#         return self.output_layer(X)\n",
    "\n",
    "\n",
    "# class Decoder(Layer):\n",
    "#     def __init__(self, units):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.output_layer = Dense(units=units)\n",
    "\n",
    "#     def call(self, X):\n",
    "#         return self.output_layer(X)\n",
    "\n",
    "def Encoder(x, units):\n",
    "    x = Dense(units, activation=tf.nn.relu)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Decoder(x, units):\n",
    "    x = Dense(units)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class AutoEncoder(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.x_in = Input(input_shape)\n",
    "        self.encoder = Encoder(units=self.units)\n",
    "        self.decoder = Decoder(units=input_shape[-1])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "located-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"auto_encoder_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  128       \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  99        \n",
      "=================================================================\n",
      "Total params: 227\n",
      "Trainable params: 227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae = AutoEncoder(32)\n",
    "ae(tf.keras.Input((320, 320, 3)))\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "spoken-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Dense, Input\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "speaking-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.output_layer = Dense(units=units, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.output_layer(X)\n",
    "\n",
    "\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_layer = Dense(units=units)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.output_layer(X)\n",
    "\n",
    "\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self, units):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder = Encoder(units=self.units)\n",
    "        self.decoder = Decoder(units=input_shape[-1])\n",
    "\n",
    "    def call(self, X):\n",
    "        Z = self.encoder(X)\n",
    "        return self.decoder(Z)\n",
    "\n",
    "    def encode(self, X):\n",
    "        return self.encoder(X)\n",
    "\n",
    "    def decode(self, Z):\n",
    "        return self.decode(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "collectible-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @AutoEncoder.testdec\n",
    "# def darkcov(filters):\n",
    "#     x = inputs = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "located-focus",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoEncoder' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-ae726f521f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ae(tf.keras.Input((320, 320, 3)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-179-f66915dd5c48>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(self, raw_input)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-179-f66915dd5c48>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoEncoder' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "ae = AutoEncoder(32)\n",
    "# ae(tf.keras.Input((320, 320, 3)))\n",
    "ae.build_graph((320, 320, 3)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "veterinary-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class darkcov(Model)\n",
    "    def __init__(self, units):\n",
    "        super(darkcov, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape)\n",
    "        self.output_layer = Dense(units=units, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.output_layer(X)\n",
    "    \n",
    "\n",
    "class Darknet(Model):\n",
    "    def __init__(self, units):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.output_layer = Dense(units=units, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.output_layer(X)\n",
    "\n",
    "\n",
    "class PredConvs(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_layer = Dense(units=units)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.output_layer(X)\n",
    "\n",
    "\n",
    "class Yolo(Model):\n",
    "    def __init__(self, units):\n",
    "        super(Yolo, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder = Encoder(units=self.units)\n",
    "        self.decoder = Decoder(units=input_shape[-1])\n",
    "\n",
    "    def call(self, X):\n",
    "        Z = self.encoder(X)\n",
    "        return self.decoder(Z)\n",
    "\n",
    "    def encode(self, X):\n",
    "        return self.encoder(X)\n",
    "\n",
    "    def decode(self, Z):\n",
    "        return self.decode(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "regulation-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class yolo(Model):\n",
    "    def __init__(self):\n",
    "        super(darknet).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.darknet = darknet()\n",
    "        self.output0 = output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "exempt-amendment",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-4f3c78f91f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# ae.build((320, 320, 3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-c19c49ef89f3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAutoEncoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "ae = AutoEncoder1(32)\n",
    "# ae.build((320, 320, 3))\n",
    "ae(tf.keras.Input((320, 320, 3)))\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "appreciated-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Add,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    LeakyReLU,\n",
    "    MaxPool2D,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "\n",
    "class DarknetCov(tf.keras.Model):\n",
    "    \"\"\" 1 Basic Conv \"\"\"\n",
    "    def __init__(self, filters, size, strides=1, batch_norm=True, name=\"darknet_conv\", **kwargs):\n",
    "        super(DarknetCov, self).__init__()\n",
    "        self.strides = strides\n",
    "        if strides == 1:\n",
    "            padding = 'same'\n",
    "        else:\n",
    "            self.zero_padding = ZeroPadding2D(((1, 0), (1, 0))) # top left half-padding\n",
    "            padding = 'valid'\n",
    "        self.conv2d = Conv2D(filters, size, strides, padding, kernel_regularizer=l2(0.0005))\n",
    "\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = BatchNormalization()\n",
    "        self.leaky_relu = LeakyReLU(alpha=0.1)\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.strides != 1:\n",
    "            x = self.zero_padding(x)  # top left half-padding\n",
    "        x = self.conv2d(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn(x)\n",
    "            x = self.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DarknetRes(tf.keras.Model):\n",
    "    \"\"\" 2 DarknetConv + 1 AddLayer \"\"\"\n",
    "    def __init__(self, filters, blocks=1, name=\"darknet_residual\", **kwargs):\n",
    "        super(DarknetRes, self).__init__()\n",
    "        self.resblocks = []\n",
    "        for _ in range(blocks):\n",
    "            self.resblocks += DarknetCov(filters//2, 1) ,\n",
    "            self.resblocks += DarknetCov(filters, 3) ,\n",
    "            self.resblocks += Add() ,\n",
    "    \n",
    "    def call(self, x):\n",
    "        prev = x \n",
    "        x = self.conv_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.add([prev, x])\n",
    "        return x \n",
    "    \n",
    "    \n",
    "\n",
    "class Darknet(tf.keras.Model):\n",
    "    def __init__(self, filters):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.filters = filters\n",
    "\n",
    "    def call(self, x):\n",
    "        x = DarknetConv(x, self.filters, 3)\n",
    "        x = DarknetBlock(x, self.filters, 1)\n",
    "        return x\n",
    "    \n",
    "    def build_graph(self, x_in):\n",
    "        x = inputs = Input(shape=x_in.shape)\n",
    "        return Model(inputs=x_in, outputs=self.call(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "stock-advancement",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_625 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (32, 32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-71cdfb0b8148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-1ba6740d8745>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknetConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknetBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-1ba6740d8745>\u001b[0m in \u001b[0;36mDarknetConv\u001b[0;34m(x, filters, size, strides, batch_norm)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# top left half-padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     x = Conv2D(filters=filters, kernel_size=size,\n\u001b[0m\u001b[1;32m     25\u001b[0m                \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.8/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    230\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                          \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_625 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (32, 32, 3)"
     ]
    }
   ],
   "source": [
    "dk = Darknet(64)\n",
    "x = tf.ones(shape=(32,32,3))\n",
    "dk(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-trout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
